{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Replication experiment\n",
    "\n",
    "This is the main notebook required to obtain the results of our replication study. The notebook is build around the concepts of predefined configuration files. These configuration files can be found within the codebase. The configuration files for different datasets and different explainers can be chosen by changing the parameters in the second codeblock. \n",
    "\n",
    "When loaded, the configuration for a replication experiment is passed to the replication function. This function is responsible for running all parts of the evaluation; quantitative, qualitative and efficiency. The results for the quantitative and efficiency studies are returned by the replication method and also stored in the `results` folder. The results of the qualitative study are stored in the folder name `qualitative`. \n",
    "\n",
    "**Be aware that the replication function can take very long to completed**. This is caused by the method averaging all scores over ten runs. If speed is required over accuracy the last line of the 2nd codeblock can be uncommented. This will make the evaluation run over one run only. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-16T03:27:06.800145400Z",
     "start_time": "2023-11-16T03:26:51.900523300Z"
    }
   },
   "outputs": [],
   "source": [
    "from ExplanationEvaluation.configs.selector import Selector\n",
    "from ExplanationEvaluation.tasks.replication import replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-16T03:27:14.622685200Z",
     "start_time": "2023-11-16T03:27:14.609736600Z"
    }
   },
   "outputs": [],
   "source": [
    "_dataset = 'bashapes' # One of: bashapes, bacommunity, treecycles, treegrids, ba2motifs, mutag\n",
    "_explainer = 'gnnexplainer' # One of: pgexplainer, gnnexplainer\n",
    "\n",
    "# Parameters below should only be changed if you want to run any of the experiments in the supplementary\n",
    "_folder = 'replication' # One of: replication, extension\n",
    "\n",
    "# PGExplainer\n",
    "config_path = f\"./ExplanationEvaluation/configs/{_folder}/explainers/{_explainer}/{_dataset}.json\"\n",
    "\n",
    "config = Selector(config_path)\n",
    "extension = (_folder == 'extension')\n",
    "\n",
    "# config.args.explainer.seeds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-16T03:29:14.161771500Z",
     "start_time": "2023-11-16T03:27:17.520735300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading syn1 dataset\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "conv3.weight\n",
      "conv3.bias\n",
      "lin.weight\n",
      "lin.bias\n",
      "dict_keys(['conv1.lin.weight', 'conv1.bias', 'conv2.lin.weight', 'conv2.bias', 'conv3.lin.weight', 'conv3.bias', 'lin.weight', 'lin.bias'])\n",
      "This model obtained: Train Acc: 0.9696, Val Acc: 1.0000, Test Acc: 1.0000.\n",
      "Run 0 with seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:31<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.49975780568187034\n",
      "time_elased: 520.0140158335367\n",
      "Run 1 with seed 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:30<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.4889298550824491\n",
      "time_elased: 512.584125995636\n",
      "Run 2 with seed 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16/60 [00:09<00:25,  1.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m (auc, auc_std), inf_time \u001B[38;5;241m=\u001B[39m \u001B[43mreplication\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextension\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\download\\RE-ParameterizedExplainerForGraphNeuralNetworks-main\\ExplanationEvaluation\\tasks\\replication.py:195\u001B[0m, in \u001B[0;36mreplication\u001B[1;34m(config, extension, run_qual, results_store)\u001B[0m\n\u001B[0;32m    192\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(s)\n\u001B[0;32m    194\u001B[0m inference_eval\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m--> 195\u001B[0m auc_score, time_score \u001B[38;5;241m=\u001B[39m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43minference_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauc_evaluation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexplainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m run_qual: \u001B[38;5;66;03m# We only run the qualitative experiment once\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     run_qualitative_experiment(explainer, indices, labels, config, explanation_labels)\n",
      "File \u001B[1;32mD:\\download\\RE-ParameterizedExplainerForGraphNeuralNetworks-main\\ExplanationEvaluation\\tasks\\replication.py:81\u001B[0m, in \u001B[0;36mrun_experiment\u001B[1;34m(inference_eval, auc_eval, explainer, indices)\u001B[0m\n\u001B[0;32m     79\u001B[0m explanations \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m tqdm(indices):\n\u001B[1;32m---> 81\u001B[0m     graph, expl \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m     explanations\u001B[38;5;241m.\u001B[39mappend((graph, expl))\n\u001B[0;32m     83\u001B[0m inference_eval\u001B[38;5;241m.\u001B[39mdone_explaining()\n",
      "File \u001B[1;32mD:\\download\\RE-ParameterizedExplainerForGraphNeuralNetworks-main\\ExplanationEvaluation\\explainers\\GNNExplainer.py:148\u001B[0m, in \u001B[0;36mGNNExplainer.explain\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    145\u001B[0m         masked_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_to_explain(feats, graph)\n\u001B[0;32m    146\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss(masked_pred, pred_label, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39medge_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreg_coefs)\n\u001B[1;32m--> 148\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    149\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    151\u001B[0m \u001B[38;5;66;03m# Retrieve final explanation\u001B[39;00m\n",
      "File \u001B[1;32mD:\\pycharm\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[0;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[1;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\pycharm\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(auc, auc_std), inf_time = replication(config.args.explainer, extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print((auc, auc_std), inf_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
